{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cd03535-7f86-47ef-92a6-a3a7b4e292c3",
   "metadata": {},
   "source": [
    "# JAX\n",
    "[jit](https://docs.jax.dev/en/latest/jit-compilation.html)\n",
    "\n",
    "python framework for mathmatic computation programming.\n",
    "\n",
    "As explained before, JAX enables operations to execute on CPU/GPU/TPU using the same code. (**JIT compiling a function**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02e998ad-6eb8-4acd-b2b7-ffc3a300dae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9441e63-1e3e-4af7-a2db-bab5fd471190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ \u001b[34;1mlambda \u001b[39;22m; a\u001b[35m:f32[]\u001b[39m. \u001b[34;1mlet\n",
      "    \u001b[39;22mb\u001b[35m:f32[]\u001b[39m = log a\n",
      "    c\u001b[35m:f32[]\u001b[39m = log 2.0:f32[]\n",
      "    d\u001b[35m:f32[]\u001b[39m = div b c\n",
      "  \u001b[34;1min \u001b[39;22m(d,) }\n"
     ]
    }
   ],
   "source": [
    "global_list = []\n",
    "\n",
    "def log2(x):\n",
    "    global_list.append(x)\n",
    "    ln_x = jnp.log(x)\n",
    "    ln_2 = jnp.log(2.0)\n",
    "    return ln_x / ln_2\n",
    "\n",
    "print(jax.make_jaxpr(log2)(3.0))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "194007cd-84a8-4dc5-9abd-575751d7001c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[JitTracer<~float32[]>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b49b74-0fa9-4406-8d77-439bade18415",
   "metadata": {},
   "source": [
    "Self-Normalizing Neural Networks\n",
    "\n",
    "computing a Scaled Exponential Linear Unit (SELU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39c61135-46c3-42b5-81d6-12124e402a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:2025-12-16 05:54:57,115:jax._src.xla_bridge:854: An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.9 ms ± 1.13 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "def selu(x, alpha=1.67, lambda_=1.05):\n",
    "  return lambda_ * jnp.where(x > 0, x, alpha * jnp.exp(x) - alpha)\n",
    "\n",
    "x = jnp.arange(1000000)\n",
    "%timeit selu(x).block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9dc3ef6c-65e5-4580-948e-ec011fefc810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263 μs ± 142 μs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "selu_jit = jax.jit(selu)\n",
    "\n",
    "# Pre-compile the function before timing...\n",
    "selu_jit(x).block_until_ready()\n",
    "\n",
    "%timeit selu_jit(x).block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8879180-ceb5-491f-9668-765f3b27bd34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
